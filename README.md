# Computer Vision 作業說明

本資料夾中包含兩組作業與一段情緒分析結果影片，說明如下。

## 檔案說明

- `old_13_exercises.ipynb`  
- `old_13_exercises.pdf`  
  - 對應課程中的 **Less Challenging** 作業內容。

- `new_13_exercises(challenging).ipynb`  
- `new_13_exercises(challenging).html`  
  - 對應課程中的 **More Challenging** 作業內容。  
  - 其中包含對 `Vlog.mp4` 進行情緒分析的程式與結果。

- `Sentiment Analysis Result.mp4`  
  - 紀錄模型對影片中人物進行情緒辨識與標註後的結果。

---

## Vlog 情緒分析結果說明

在 `new_13_exercises(challenging).ipynb` 中，模型針對 `Vlog.mp4` 進行逐幀的情緒分類。  
實際結果顯示：影片中人物在很大比例的時間被模型判定為 **「厭惡（disgust）」**。  
這樣的現象可能來自以下幾個原因：

1. **訓練資料來源與表情風格差異**  
   模型的訓練資料多為「演員在控制良好的實驗或拍攝環境下，誇張表演單一情緒」的影像。在這類資料中，各情緒通常具備非常明顯、典型的臉部特徵（如眉毛、嘴角、眼神等）。  
   因此，模型在推論時，傾向只有當表情非常接近訓練集中的「標準樣本」時，才會自信地歸類為某一種情緒；一旦真實影片中的表情較自然、收斂或不那麼誇張，就可能被模型誤判或偏向某幾個類別。

2. **真實情緒較複雜，與訓練標籤的「單一情緒」假設不符**  
   訓練資料大多是「一張影像只標註一種主要情緒」，  
   但 `Vlog.mp4` 中人物的表情可能同時帶有：  
   - 輕微的疲憊與憂鬱、  
   - 一點點欣慰、  
   - 或其他混合情緒。  
   這些複雜、漸變或混合的情緒狀態，其實很難被單一情緒標籤正確描述，也超出模型原本訓練時的假設，導致模型無法精準識別，只能在七個類別中「選一個最像的」。

3. **情緒類別數量有限，導致「最接近但不一定正確」的分類**  
   本模型僅有七種情緒類別可選擇。  
   在真實情境中，如果人物的情緒並不完全對應到這七類之一，模型仍必須在七類中硬性選擇。  
   於是可能出現：
   - 兩個或多個類別的機率接近，但模型仍被迫輸出機率最高者；  
   - 在特定臉部特徵較不明顯或畫面品質較差的情況下，模型可能偏向習慣性選擇某一類（例如「厭惡」），即使從人類觀察來看，實際感受更接近「悲傷」、「無奈」或「複雜情緒」。

---

## 小結

整體而言，`Vlog.mp4` 被大量判定為「厭惡」並不代表影片中的人物真的長時間處於厭惡情緒，而是反映出：

- 訓練資料與真實影像之間的落差（domain shift）、  
- 單一情緒標籤無法充分描述真實世界混合情緒、  
- 以及類別數量有限且必須「擇一分類」的模型設計限制。

